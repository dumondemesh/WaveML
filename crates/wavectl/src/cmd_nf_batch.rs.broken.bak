use std::fs::{self, File};
use std::io::{self, Write};
use std::path::PathBuf;
use clap::Parser;
use rayon::prelude::*;
use serde::Serialize;
use serde_json::Value;
use tracing::{info, error};

#[derive(Parser, Debug)]
pub struct NfBatchArgs {
    /// Explicit list of inputs (repeatable)
    #[arg(long = "input")]
    pub inputs: Vec<PathBuf>,

    /// Read file list from a text file (one path per line)
    #[arg(long = "list")]
    pub list: Option<PathBuf>,

    /// Output format: json or csv
    #[arg(long = "format", default_value = "json")]
    pub format: String,

    /// Output file (optional). If omitted, prints to stdout.
    #[arg(long = "out")]
    pub out: Option<PathBuf>,

    /// Number of threads (0 = rayon default, 1 = serial, N>1 fixed)
    #[arg(long = "jobs", default_value_t = 0usize)]
    pub jobs: usize,
}

#[derive(Serialize)]
struct Row { input: String, nf_id: String }

fn read_json(path: &PathBuf) -> anyhow::Result<Value> {
    let s = fs::read_to_string(path)?;
    let v: Value = serde_json::from_str(&s)?;
    Ok(v)
}
fn nf_id_hex(v: &Value) -> anyhow::Result<String> { Ok(waveforge::nf_id_hex(v)?) }

pub fn run_nf_batch(args: &NfBatchArgs) -> anyhow::Result<()> {
    wave_logging::init();
    let mut items: Vec<PathBuf> = vec![];
    items.extend(args.inputs.iter().cloned());
    if let Some(list) = &args.list {
        let s = fs::read_to_string(list)?;
        for line in s.lines() {
            let t = line.trim();
            if t.is_empty() || t.starts_with('#') { continue; }
            items.push(PathBuf::from(t));
        }
    }
    items.sort_by(|a,b| a.as_os_str().cmp(b.as_os_str()));
    info!(count = items.len(), jobs = args.jobs, "nf-batch start");

    let results: Vec<anyhow::Result<Row>> = if args.jobs == 1 {
        items.iter().map(|p| {
            let v = read_json(p)?; let id = nf_id_hex(&v)?;
            Ok(Row{ input: p.to_string_lossy().into_owned(), nf_id: id })
        }).collect()
    } else {
        let pool = if args.jobs > 1 {
            Some(rayon::ThreadPoolBuilder::new().num_threads(args.jobs).build()?)
        } else { None };
        let f = || {
            items.par_iter().map(|p| {
                let v = read_json(p)?; let id = nf_id_hex(&v)?;
                Ok(Row{ input: p.to_string_lossy().into_owned(), nf_id: id })
            }).collect::<Vec<anyhow::Result<Row>>>()
        };
        match pool { Some(pool) => pool.install(f), None => f() }
    };

    let mut rows: Vec<Row> = Vec::with_capacity(results.len());
    for r in results { match r {
        Ok(row) => rows.push(row),
        Err(e) => { error!(err=?e, "nf-batch item failed"); return Err(e); }
    }}
    rows.sort_by(|a,b| a.input.cmp(&b.input));

    match args.format.as_str() {
        "json" => {
            let val = serde_json::to_value(&rows)?;
            if let Some(out) = &args.out {
                if let Some(dir) = out.parent() { fs::create_dir_all(dir)?; }
                fs::write(out, serde_json::to_string_pretty(&val)?)?;
                println!("[nf-batch] Wrote {}", out.display());
            } else { println!("{}", serde_json::to_string_pretty(&val)?); }
        }
        "csv" => {
            let mut wtr: Box<dyn Write> = if let Some(out) = &args.out {
                if let Some(dir) = out.parent() { fs::create_dir_all(dir)?; }
                Box::new(File::create(out)?)
            } else { Box::new(io::stdout()) };
            let mut csvw = csv::Writer::from_writer(&mut wtr);
            for r in rows { csvw.serialize(r)?; }
            csvw.flush()?;
            if let Some(out) = &args.out { println!("[nf-batch] Wrote {}", out.display()); }
        }
        x => anyhow::bail!("unknown --format: {}", x)
    }
    Ok(())
}
